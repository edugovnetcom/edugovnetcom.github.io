<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Parallel Sorting in Theory and in Practice I - EduGovNet.com</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Parallel Sorting in Theory and in Practice I" />
<meta property="og:description" content="We&rsquo;re going to begin our discussion of parallel algorithms. We&rsquo;ll do this by giving a parallel version of quick_sort_plus. We finish this entry by extending the &ldquo;Almost the Master Theorem&rdquo; to include cases where f(n) = cn^alpha*log_2(n). In our next entry, we&rsquo;ll introduce merge_sort as well as a couple different parallel versions of it. We&rsquo;ll also discuss both the theoretical and practical runtimes for these functions." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/parallel-sorting-in-theory-and-in-practice-i/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2021-07-23T14:26:40-04:00" />
<meta property="article:modified_time" content="2021-07-23T14:26:40-04:00" />


		<meta itemprop="name" content="Parallel Sorting in Theory and in Practice I">
<meta itemprop="description" content="We&rsquo;re going to begin our discussion of parallel algorithms. We&rsquo;ll do this by giving a parallel version of quick_sort_plus. We finish this entry by extending the &ldquo;Almost the Master Theorem&rdquo; to include cases where f(n) = cn^alpha*log_2(n). In our next entry, we&rsquo;ll introduce merge_sort as well as a couple different parallel versions of it. We&rsquo;ll also discuss both the theoretical and practical runtimes for these functions."><meta itemprop="datePublished" content="2021-07-23T14:26:40-04:00" />
<meta itemprop="dateModified" content="2021-07-23T14:26:40-04:00" />
<meta itemprop="wordCount" content="1831">
<meta itemprop="keywords" content="Parallel Sorting,omp,Parallel Computing," />
		<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Parallel Sorting in Theory and in Practice I"/>
<meta name="twitter:description" content="We&rsquo;re going to begin our discussion of parallel algorithms. We&rsquo;ll do this by giving a parallel version of quick_sort_plus. We finish this entry by extending the &ldquo;Almost the Master Theorem&rdquo; to include cases where f(n) = cn^alpha*log_2(n). In our next entry, we&rsquo;ll introduce merge_sort as well as a couple different parallel versions of it. We&rsquo;ll also discuss both the theoretical and practical runtimes for these functions."/>

	<link rel="stylesheet" href="/css/style.css">
	<link rel="stylesheet" href="/css/custom.css">
	<link rel="shortcut icon" href="/images/favicon.png">
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo logo--mixed">
		<a class="logo__link" href="/" title="EduGovNet.com" rel="home">
			<div class="logo__item logo__imagebox">
					<img class="logo__img" src="/images/aleph_heiroglyph.png">
				</div><div class="logo__item logo__text">
					<div class="logo__title">EduGovNet.com</div>
					<div class="logo__tagline">Let&#39;s strive to have our mistakes be honest mistakes.</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">
				<i class='fa fa-heart'></i>
				<span class="menu__text">Home</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/contact_us/">
				
				<span class="menu__text">Contact Us</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Parallel Sorting in Theory and in Practice I</h1>
			<div class="post__meta meta"><div class="meta__item-author meta__item">
	<svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2 0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class="meta__text">Mike</span>
</div>
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-07-23T14:26:40-04:00">2021-07-23</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/algorithms/" rel="category">Algorithms</a>
	</span>
</div></div>
		</header>
		<figure class="post__thumbnail">
			<img src="/images/trainyard_with_lights.jpg" alt="Parallel Sorting in Theory and in Practice I">
		</figure>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
  <ul>
    <li><a href="#parallel-quick_sort_plus">Parallel quick_sort_plus()</a></li>
    <li><a href="#parallel_kth_smallest">parallel_kth_smallest()</a></li>
    <li><a href="#parallel_pivot">parallel_pivot()</a></li>
    <li><a href="#case-4-almost-the-master-theorem">Case #4 (almost the master theorem)</a></li>
  </ul>
</nav>
	</div>
</div><div class="content post__content clearfix">
			<p><span class="first-letter">W</span>e&rsquo;re going to begin our discussion of parallel algorithms. We&rsquo;ll do this by giving a parallel version of <code>quick_sort_plus</code>. In the next entry (<a href="/blog/parallel-sorting-in-theory-and-in-practice-ii/">Parallel Sorting in Theory and in Practice (II)</a>), we&rsquo;ll introduce another sorting algorithm, <code>merge_sort</code>, and show how it can be made to run in parallel in a couple of different ways. The first is simpler, but isn&rsquo;t as fast as the second, more complicated implementation. The parallel function we provide in this entry probably shouldn&rsquo;t be used in a real-world situation. It&rsquo;s not actually that fast. What&rsquo;s more, the one advantage that the serial version of <code>quick_sort</code> has over <code>merge_sort</code>, the fact that it doesn&rsquo;t require much memory to work doesn&rsquo;t even hold. That&rsquo;s because it calls a function, <code>parallel_pivot</code>, which has to make a copy of the input array, and so it uses about as much extra memory as merge_sort does. We start with it <code>parallel_quick_sort_plus</code>, because it&rsquo;s simpler to understand than <code>parallel_merge_sort</code>.</p>
<p>Here&rsquo;s a parallel implementation <code>quick_sort_plus</code> in C++</p>
<h2 id="parallel-quick_sort_plus">Parallel quick_sort_plus()</h2>
<div class="highlight"><div style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#2b91af">void</span> parallel_quick_sort_plus(<span style="color:#2b91af">int64_t</span>* array, <span style="color:#2b91af">int64_t</span> length, <span style="color:#2b91af">int16_t</span> n_threads)
{
  <span style="color:#00f">if</span> (!array) <span style="color:#00f">return</span>;
  <span style="color:#00f">if</span> (length &lt; 2) <span style="color:#00f">return</span>;

  <span style="color:#2b91af">int16_t</span> max_threads = omp_get_max_threads();
  <span style="color:#2b91af">int16_t</span> threads = (max_threads &lt; n_threads) ? max_threads : n_threads;
  <span style="color:#2b91af">int16_t</span> l_threads, r_threads;

  omp_set_num_threads(threads);

  <span style="color:#2b91af">int64_t</span> h = length / 2;

  parallel_kth_smallest(array, h, length, threads);

  <span style="color:#00f">if</span> (threads &gt; 1)
  {
    l_threads = threads / 2;
    r_threads = threads - l_threads;

    <span style="color:#2b91af">int</span> i;
    omp_set_nested(1);
    <span style="color:#00f">#pragma omp parallel for private(i) shared(l_threads, r_threads, array, length)
</span><span style="color:#00f"></span>    <span style="color:#00f">for</span> (i = 0; i &lt; 2; i++)
    {
      <span style="color:#00f">if</span> (i == 0)
      {
        omp_set_num_threads(l_threads);
        parallel_quick_sort_plus(array, h, l_threads);
      }
      <span style="color:#00f">else</span>
      {
        omp_set_num_threads(r_threads);
        parallel_quick_sort_plus(&amp;array[h], length - h, r_threads);
      }
    }
  }
  <span style="color:#00f">else</span>
  {
    <span style="color:#008000">// do it serially //
</span><span style="color:#008000"></span>    quick_sort(array, h);
    quick_sort(&amp;array[h], length - h);
  }
}</code></pre></td></tr></table>
</div>
</div>
<p>We use <code>omp.h</code> to make it run in parallel. You probably noticed the bizarre use of <code>for (i = 0; i &lt; 2; i++)</code> with an <code>if</code> <code>else</code> statement. We didn&rsquo;t want to write it that way, but we couldn&rsquo;t get nested parallelism to work when we tried implementing the function with parallel <em>sections</em> or <em>tasks</em>. Without nested parallelism, the recursive calls wouldn&rsquo;t run in parallel.</p>
<p>There&rsquo;s nothing earth-shattering going on here. If you can follow the serial version of <code>quick_sort_plus</code> (given here <a href="/blog/finding-the-median-and-an-application-to-sorting/#quick_sort_plus">Finding the Median and an Application to Sorting</a>), then this should make sense.</p>
<p>You&rsquo;ll notice we call <code>parallel_kth_smallest</code> it&rsquo;s a bit more complicated than the serial version of it. It provides the evenly-split pivot, which makes <code>quick_sort_plus</code> work in guaranteed (O(n\log_2(n))) steps.</p>
<p>Here&rsquo;s our implementation of that function.</p>
<h2 id="parallel_kth_smallest">parallel_kth_smallest()</h2>
<div class="highlight"><div style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#2b91af">void</span> parallel_kth_smallest(<span style="color:#2b91af">int64_t</span>* array, <span style="color:#2b91af">int64_t</span> k,
  <span style="color:#2b91af">int64_t</span> length, <span style="color:#2b91af">int16_t</span> n_threads)
{
  <span style="color:#008000">// CHUNK_SIZE is usually 5
</span><span style="color:#008000"></span>  <span style="color:#00f">if</span> (length &lt;= CHUNK_SIZE)
  {
    bubble_sort(array, length);
    <span style="color:#00f">return</span>;
  }
  <span style="color:#2b91af">int16_t</span> max_threads = omp_get_max_threads();
  <span style="color:#2b91af">int16_t</span> threads = (max_threads &lt; n_threads) ? max_threads : n_threads;
  <span style="color:#2b91af">int16_t</span> tid;

  omp_set_num_threads(threads);

  <span style="color:#2b91af">int64_t</span> m_length = ceil(length, CHUNK_SIZE);
  <span style="color:#2b91af">int64_t</span>* medians = <span style="color:#00f">new</span> <span style="color:#2b91af">int64_t</span>[m_length];
  <span style="color:#2b91af">int64_t</span> i, j, tmp_length, m_index;

  omp_set_nested(1);
  <span style="color:#00f">#pragma omp parallel for private(i, j, tmp_length, m_index)
</span><span style="color:#00f"></span>    shared(array, medians, m_length)
  <span style="color:#00f">for</span> (j = 0; j &lt; m_length; j++)
  {
    i = CHUNK_SIZE*j;
    tmp_length = ((i + CHUNK_SIZE) &lt;= length) ? CHUNK_SIZE : length - i;
    m_index = i + (tmp_length / 2);
    bubble_sort(&amp;array[i], tmp_length);
    medians[j] = array[m_index];
  }

  <span style="color:#008000">// Now for the recursive step
</span><span style="color:#008000"></span>  parallel_kth_smallest(medians, m_length / 2, m_length, threads);

  <span style="color:#008000">// Now for parallel pivot!
</span><span style="color:#008000"></span>
  m_index = parallel_pivot(array, medians[m_length / 2], length, threads);

  <span style="color:#008000">// clean up medians!
</span><span style="color:#008000"></span>  <span style="color:#00f">delete</span> medians;

  <span style="color:#00f">if</span> (m_index == k) <span style="color:#00f">return</span>;

  <span style="color:#008000">// k is to the right side
</span><span style="color:#008000"></span>  <span style="color:#00f">if</span> (m_index &lt; k)
  {
    parallel_kth_smallest(&amp;array[m_index+1], k - (m_index + 1),
      length - (m_index + 1), threads);
    <span style="color:#00f">return</span>;
  }

  <span style="color:#008000">// k is to the left side
</span><span style="color:#008000"></span>  parallel_kth_smallest(array, k, m_index, threads);
}</code></pre></td></tr></table>
</div>
</div>
<p>The main difference between this and the serial version is that we compute the medians array in parallel. Because we&rsquo;re computing in parallel, we cannot move the medians to the initial segment of <code>array</code>, so we have to allocate a new array for them. We&rsquo;ll have to allocate another array for similar reasons in <code>parallel_pivot</code>.</p>
<p>Here&rsquo;s our implementation of that function.</p>
<h2 id="parallel_pivot">parallel_pivot()</h2>
<div class="highlight"><div style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4">
<table style="border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#2b91af">int64_t</span> parallel_pivot(<span style="color:#2b91af">int64_t</span>* array, <span style="color:#2b91af">int64_t</span> value,
  <span style="color:#2b91af">int64_t</span> length, <span style="color:#2b91af">int16_t</span> n_threads)
{
  <span style="color:#00f">if</span> (length &lt; 2) <span style="color:#00f">return</span> 0;
  <span style="color:#2b91af">int16_t</span> max_threads = omp_get_max_threads();
  <span style="color:#2b91af">int16_t</span> threads = (max_threads &lt; n_threads) ? max_threads : n_threads;

  <span style="color:#008000">//omp_set_num_threads(threads);
</span><span style="color:#008000"></span>
  <span style="color:#2b91af">int64_t</span> i, tid, offset;
  <span style="color:#2b91af">int64_t</span> smaller_count[threads+1];
  <span style="color:#2b91af">int64_t</span> larger_count[threads+1];

  <span style="color:#008000">// Doing this in parallel isn&#39;t worth it.
</span><span style="color:#008000"></span>  <span style="color:#00f">for</span> (i = 0; i &lt; threads+1; i++)
  {
    smaller_count[i] = 0;
    larger_count[i] = 0;
  }

  <span style="color:#00f">#pragma omp parallel for private(i, tid)
</span><span style="color:#00f"></span>    shared(smaller_count, array, length)
  <span style="color:#00f">for</span> (i = 0; i &lt; length; i++)
  {
    tid = omp_get_thread_num();
    <span style="color:#00f">if</span> (array[i] &lt; value)
    {
      smaller_count[tid+1]++;
    }
    <span style="color:#00f">else</span>{
      larger_count[tid+1]++;
    }
  }

  <span style="color:#008000">// Doing this in parallel isn&#39;t worth it.
</span><span style="color:#008000"></span>  <span style="color:#00f">for</span> (i = 1; i &lt; threads+1; i++)
  {
    smaller_count[i] += smaller_count[i-1];
    larger_count[i] += larger_count[i-1];
  }
  <span style="color:#008000">/*
</span><span style="color:#008000">  smaller_count[threads] = the total number of elements less than value
</span><span style="color:#008000">  this is the value we will return.
</span><span style="color:#008000">  */</span>

  <span style="color:#2b91af">int64_t</span>* array_copy = <span style="color:#00f">new</span> <span style="color:#2b91af">int64_t</span>[length];

  <span style="color:#00f">#pragma omp parallel for private(i, tid, offset)
</span><span style="color:#00f"></span>    shared(smaller_count, array, array_copy, length, threads)
  <span style="color:#00f">for</span> (i = 0; i &lt; length; i++)
  {
    tid = omp_get_thread_num();
    <span style="color:#00f">if</span> (array[i] &lt; value)
    {
      <span style="color:#008000">// offset equals the old number, then we increase it by 1
</span><span style="color:#008000"></span>      offset = smaller_count[tid]++;
    }
    <span style="color:#00f">else</span>
    {
      <span style="color:#008000">// offset equals the old number, then we increase it by 1
</span><span style="color:#008000"></span>      offset = smaller_count[threads] + (larger_count[tid]++);
    }
    array_copy[offset] = array[i];
    
  }

  <span style="color:#00f">#pragma omp parallel for private(i) shared(array, array_copy)
</span><span style="color:#00f"></span>  <span style="color:#00f">for</span> (i = 0; i &lt; length; i++)
  {
    array[i] = array_copy[i];
  }

  <span style="color:#008000">// clean up!!
</span><span style="color:#008000"></span>  <span style="color:#00f">delete</span> array_copy;

  <span style="color:#00f">return</span> smaller_count[threads];
}</code></pre></td></tr></table>
</div>
</div>
<p>We perform a &ldquo;pivot&rdquo; in parallel, i.e. move everything less than <code>value</code> to the left section of <code>array</code>, and everything else to the right by first creating two arrays of counters &ndash; two for each thread. We&rsquo;re going to have each thread count how many smaller values it sees and how many larger values it sees. This obviously works in parallel, because each thread is updating different elements of the two arrays. Then, once we&rsquo;re done with that, we perform what is sort of like an integral. We end up with</p>
<p>\[ \text{smaller_count}[i] = \sum\limits_{j = 0}^{i-1} \text{smaller}_j\]</p>
<p>where \(\text{smaller}_j\) is the number of elements less than <code>value</code> seen by thread \(j\). It&rsquo;s similar for \(\text{larger_count}[i]\).</p>
<p>When the scheduling of the threads over the elements of <code>array</code> remains fixed from one for loop to another, this allows us to move the elements from <code>array</code> to <code>array_copy</code> without having to worry about any two threads writing to the same place. Fortunately for us, the default omp schedule does stay the same with for loops of the same length. If you&rsquo;re using something other than omp, or just want to make sure that this works properly, you&rsquo;ll have to set the schedule yourself.</p>
<p>This is what we do in the next for loop, and then there&rsquo;s a final for loop which copies the values of <code>array_copy</code> back to <code>array</code>, so that it&rsquo;s in the state it should be.</p>
<p>This function returns <code>smaller_count[threads]</code>, which is equal to the total number of elements of <code>array</code> which are strictly less than <code>value</code>. With this, we have made <code>quick_sort_plus</code> parallel.</p>
<p>Unfortunately, there&rsquo;s not much of a reason to implement <code>quick_sort_plus</code> in parallel, because it&rsquo;s based on <code>quick_sort_plus</code>, which is quite slow for an \(O(n\log_2(n))\) algorithm. We ran a test, sorting 200 million elements. Ordinary <code>quick_sort</code> finished in 25.4 seconds, while our <code>parallel_quick_sort_plus</code> took a whopping 87.7 seconds with 8 cores and 16 threads (Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz). That&rsquo;s not a lot of threads, but even if you&rsquo;re running on a computer with hundreds or perhaps thousands of threads, there&rsquo;s still no point in using this function, because parallel <code>merge_sort</code> would be faster.</p>
<p>We&rsquo;ll implement <code>merge_sort</code> in the next entry. For the rest of this entry, we will revisit the &ldquo;<a href="/blog/more-on-sorting-and-analyzing-run-time-complexity/#corollary-almost-the-master-theorem">Almost the Master Theorem</a>&rdquo;. We originally proved it in More on Sorting and Analyzing Run Time Complexity.</p>
<p>Let&rsquo;s consider what happens when \(T(n) = f(n) + aT(\left\lceil \frac{n}{b}\right\rceil)\) is a recurrence relation, \(f(n) = cn^{\alpha}\log_2(n)\) and \(a = b^{\alpha}\). In this case the &ldquo;Almost the Master Theorem&rdquo; tells us that if we instead consider \(f_{\epsilon}(n) = cn^{\alpha + \epsilon}\), for some tiny \(\epsilon &gt; 0\), then \(T(n) \in O(f_{\epsilon}(n)) \). That isn&rsquo;t quite satisfying enough.</p>
<p>Notice that when we consider \(T(b^k)\), as we did in More on Sorting and Analyzing Run Time Complexity (<a href="/blog/more-on-sorting-and-analyzing-run-time-complexity/#mjx-eqn:5">equation 5</a>), we get</p>
<p>\[ T(b^k) = c\sum\limits_{i=0}^{k} a^{i}(b^{\alpha})^{k-i} \log_b(b^{k-i})\log_2(b)) \tag{1}\label{1}\]</p>
<p>which is identical to equation (5) from that entry, except for the \(\log\) terms at the end. Also, notice that \(\log_2(b)\) can be absorbed into the constant \(c\), so the base of the logarithm can be changed to \(b\) without affecting much.</p>
<p>Since we assumed that \(a = b^{\alpha}\), we have</p>
<p>\[ a^{i}(b^{\alpha})^{k-i} = (b^{\alpha})^{i} (b^{\alpha})^{k-i} = (b^{\alpha})^k = (b^k)^{\alpha} \tag{2}\label{2}\]</p>
<p>If we let \(c' = c\log_2(b)\), then combining equations (1) and (2) gives us</p>
<p>\[ c'(b^k)^{\alpha} \sum\limits_{i=0}^{k} \log_b(b^{k-i}) \tag{3}\label{3} \]</p>
<p>Which is easily seen to give us
\[ c'(b^k)^{\alpha} \sum\limits_{i=0}^{k} {k-i} \tag{4}\label{4} \]</p>
<p>If we do the sum in the opposite order, we get</p>
<p>\[ c'(b^k)^{\alpha} \sum\limits_{i=0}^{k} {i} \tag{5}\label{5} \]</p>
<p>A nice arithmetic sum, which is equal to</p>
<p>\[ c'(b^k)^{\alpha} \frac{k(k+1)}{2} \tag{6}\label{6}\]
Substituting \(n = b^k\), then gives us
\[ T(n) = c&rsquo;n^{\alpha} \frac{ \log_b(n)(\log_b(n) + 1) }{ 2 } \tag{7}\label{7}\]</p>
<p>So far, we&rsquo;ve only shown that this holds when \(n\) is a power of \(b\), but in a very similar way to how we proved case 3 of the &ldquo;<a href="/blog/more-on-sorting-and-analyzing-run-time-complexity/#corollary-almost-the-master-theorem">Almost the Master Theorem</a>&rdquo; in More on Sorting and Analyzing Run Time Complexity, combining <a href="/blog/more-on-sorting-and-analyzing-run-time-complexity/#lemma-2">lemma (2)</a> with <a href="/blog/more-on-sorting-and-analyzing-run-time-complexity/#lemma-1">lemma (1)</a> from that entry, we have</p>
<p>\[ T(n) \leq c&rsquo;b^{\alpha}(n)^{\alpha} [ \frac{(\log_b(n)+1)\log_b(n)}{2} + \log_b(n) + 1 ] \tag{8}\label{8}\]</p>
<p>This can be shown to be in</p>
<p>\[O(\log_2(n)^{2} n^{\alpha}) \tag{9}\label{9}\]</p>
<p>So, for now, this will be case 4 of the &ldquo;Almost the Master Theorem&rdquo;.</p>
<p>To recap:</p>
<h2 id="case-4-almost-the-master-theorem">Case #4 (almost the master theorem)</h2>
<p>Let \(T(n) = f(n) + aT(\left\lceil \frac{n}{b}\right\rceil) \), where \( f(b) = cn^{\alpha}\log_2(n)\), then</p>
<p>\(T(n) \in O(\log_2(n)^{2}n^{\alpha}) \)</p>
<p><strong>Proof</strong></p>
<p>Given above.</p>
<p>That&rsquo;s it for this entry. We continue this discussion in the next entry, <a href="/blog/parallel-sorting-in-theory-and-in-practice-ii/">Parallel Sorting in Theory and in Practice (II)</a>.</p>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/parallel-sorting/" rel="tag">Parallel Sorting</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/omp/" rel="tag">omp</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/parallel-computing/" rel="tag">Parallel Computing</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/blog/computing-with-permutations-inverses-cycles-and-more/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Computing With Permutations, Inverses, Cycles, and More!</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/blog/parallel-sorting-in-theory-and-in-practice-ii/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Parallel Sorting in Theory and in Practice II</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2021 EduGovNet.com.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>
<script src="/js/custom.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js?config=TeX-AMS-MML_HTMLorMML" async></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\[','\]']],
      processEscapes: true,
      processEnvironments: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      TeX: { equationNumbers: { autoNumber: "AMS" },
           extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
  });
</script>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i &lt; all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>
/blog/parallel-sorting-in-theory-and-in-practice-i/
<img style="display:none;" src="https://api.edugovnet.com/?page=%2fblog%2fparallel-sorting-in-theory-and-in-practice-i%2f" />
</body>
</html>